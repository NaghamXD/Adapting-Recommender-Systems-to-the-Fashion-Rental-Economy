{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import os\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "\n",
    "import pandas as pd\n",
    "from resources.constants import *\n",
    "\n",
    "def density_of_transactions(num_transactions, num_customers, num_articles):\n",
    "    return num_transactions / (num_customers * num_articles)\n",
    "\n",
    "HNM_DATASET_PATH = r\"resources\\other_datasets\\HnM_dataset\\transactions_train.csv\"\n",
    "NETFLIX_PRIZE_COMPETITION_PATH = r\"resources\\other_datasets\\Netflix_prize_competition\"\n",
    "RENT_THE_RUNWAY_DATASET_PATH = r\"resources\\other_datasets\\renttherunway_final_dataset\\renttherunway_final_data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtr_df = pd.read_json(RENT_THE_RUNWAY_DATASET_PATH, lines=True)\n",
    "rtr_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtr_df[\"user_id\"].value_counts().describe(percentiles=[0.25, 0.5, 0.6, 0.68, 0.7, 0.75, 0.9, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "\n",
    "num_articles = rtr_df[\"item_id\"].nunique()\n",
    "num_customers = rtr_df[\"user_id\"].nunique()\n",
    "num_transactions = rtr_df.shape[0]\n",
    "print(num_articles, num_customers, num_transactions)\n",
    "\n",
    "rtr_density = density_of_transactions(num_transactions, num_customers, num_articles)\n",
    "print(f\"Density of transactions: {Decimal(rtr_density):.2E}, Number of users: {Decimal(num_customers)}, Number of outfits: {Decimal(num_articles)}, Number of orders: {Decimal(num_transactions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hnm_df = pd.read_csv(HNM_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hnm_df = hnm_df.drop_duplicates(subset=[\"article_id\", \"customer_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_articles = hnm_df[\"article_id\"].nunique()\n",
    "num_customers = hnm_df[\"customer_id\"].nunique()\n",
    "num_transactions = hnm_df.shape[0]\n",
    "print(num_articles, num_customers, num_transactions)\n",
    "\n",
    "hnm_density = density_of_transactions(num_transactions, num_customers, num_articles)\n",
    "hnm_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#Netflix prize competition\n",
    "\n",
    "# data_paths = [os.path.join(NETFLIX_PRIZE_COMPETITION_PATH, file) for file in os.listdir(NETFLIX_PRIZE_COMPETITION_PATH)]\n",
    "# netflix_df = pd.read_csv(data_paths[0], header=None, names=[\"customer_id\", \"rating\", \"date\"])\n",
    "# for path in tqdm(data_paths[1:]):\n",
    "#     netflix_df = pd.concat([netflix_df, pd.read_csv(path, header=None, names=[\"customer_id\", \"rating\", \"date\"])])\n",
    "# tqdm.pandas()\n",
    "# current_movie_id = -1\n",
    "\n",
    "# def parse_dataset_movies(customer_id, rating, data):\n",
    "#     global current_movie_id\n",
    "\n",
    "#     if customer_id.endswith(\":\"):\n",
    "#         current_movie_id = int(customer_id[:-1])\n",
    "#         return None\n",
    "#     else:\n",
    "#         return current_movie_id\n",
    "\n",
    "# netflix_df[\"movie_id\"] = netflix_df.progress_apply(lambda row: parse_dataset_movies(row[\"customer_id\"], row[\"rating\"], row[\"date\"]), axis=1)\n",
    "# netflix_df.to_pickle(os.path.join(NETFLIX_PRIZE_COMPETITION_PATH, \"netflix_df.gz\"), compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df = pd.read_pickle(os.path.join(NETFLIX_PRIZE_COMPETITION_PATH, \"netflix_df.gz\"), compression=\"gzip\")\n",
    "netflix_df = netflix_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_value_counts = netflix_df[\"customer_id\"].value_counts()\n",
    "netflix_value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_value_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_movies = netflix_df[\"movie_id\"].nunique()\n",
    "num_customers = netflix_df[\"customer_id\"].nunique()\n",
    "num_ratings = netflix_df.shape[0]\n",
    "num_movies, num_customers, num_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "netflix_density = density_of_transactions(num_ratings, num_customers, num_movies)\n",
    "print(f\"Density of transactions: {Decimal(netflix_density):.2E}, Number of movies: {Decimal(num_movies)}, Number of customers: {Decimal(num_customers)}, Number of ratings: {Decimal(num_ratings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "triplets_df = pd.read_csv(USER_ACTIVITY_TRIPLETS_CSV_PATH, sep=CSV_SEPARATOR)\n",
    "outfits_df = pd.read_csv(OUTFITS_CSV_PATH, sep=CSV_SEPARATOR)\n",
    "\n",
    "# Append orders from before 2020 to the evaluated dataset\n",
    "original_orders_df = pd.read_csv(ORIGINAL_ORDERS_CSV_PATH, sep=CSV_SEPARATOR)\n",
    "triplets_df = pd.concat([triplets_df, original_orders_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets_df = triplets_df.drop_duplicates(subset=[\"customer.id\", \"outfit.id\"]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = triplets_df[\"customer.id\"].nunique()\n",
    "num_outfits = triplets_df[\"outfit.id\"].nunique()\n",
    "num_orders = triplets_df.shape[0]\n",
    "num_users, num_outfits, num_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "\n",
    "vibrent_density = density_of_transactions(num_orders, num_users, num_outfits)\n",
    "print(f\"Density of transactions: {Decimal(vibrent_density):.2E} ({vibrent_density}), Number of users: {Decimal(num_users)}, Number of outfits: {Decimal(num_outfits)}, Number of orders: {Decimal(num_orders)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfit_group_dict = outfits_df[[\"id\", \"group\"]].set_index(\"id\").to_dict()[\"group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets_df[\"outfit_group\"] = triplets_df[\"outfit.id\"].map(outfit_group_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets_df = triplets_df.drop_duplicates(subset=[\"customer.id\", \"outfit_group\"]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = triplets_df[\"customer.id\"].nunique()\n",
    "num_outfits = triplets_df[\"outfit_group\"].nunique()\n",
    "num_orders = triplets_df.shape[0]\n",
    "num_users, num_outfits, num_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vibrent_density = density_of_transactions(num_orders, num_users, num_outfits)\n",
    "print(f\"Density of transactions: {Decimal(vibrent_density):.2E} ({vibrent_density}), Number of users: {Decimal(num_users)}, Number of outfits: {Decimal(num_outfits)}, Number of orders: {Decimal(num_orders)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtr_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "DENSITIES = {\n",
    "    \"H&M Fashion\": 0.00019172855246088317,\n",
    "    \"Netflix Prize\": 0.01177557662406687,\n",
    "    \"Clothing Rental Groups\": 0.0011599473470511846,\n",
    "    \"Clothing Rental Individual\": 0.0007687068402113402,\n",
    "    \"Rent The Runway\": 0.0003117665293831097,\n",
    "    \"Goodreads\": 1.6260964205629808e-05,\n",
    "    \"Amazon Fashion\": 6.3e-06,\n",
    "    \"Book Rental\": 3.4083453369004934e-05\n",
    "}\n",
    "\n",
    "densities_df = pd.DataFrame.from_dict(DENSITIES, orient=\"index\", columns=[\"density\"])\n",
    "densities_df.sort_values(by=\"density\", ascending=False, inplace=True)\n",
    "densities_df.index.name = \"dataset\"\n",
    "densities_df = densities_df.reset_index()\n",
    "\n",
    "ax = densities_df.plot(kind=\"bar\", x=\"dataset\", y=\"density\", title=\"Density of datasets\", color=\"skyblue\", legend=False)\n",
    "#ax.set_ylim(0, max(DENSITIES.values()) + 0.0015)\n",
    "ax.set_ylabel(\"Density\")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylim(1e-6, 1e-1)\n",
    "ax.set_xticklabels(densities_df[\"dataset\"], rotation=45)\n",
    "\n",
    "# Annotate the value of each bar\n",
    "for i in ax.patches:\n",
    "    ax.annotate(format(i.get_height(), '.6f'), \n",
    "                (i.get_x() + i.get_width() / 2., i.get_height()), \n",
    "                ha = 'center', va = 'center', \n",
    "                xytext = (0, 10), \n",
    "                textcoords = 'offset points')\n",
    "\n",
    "plt.savefig(\"reports/figures/density_of_datasets.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start of the LaTeX table\n",
    "latex_table = r\"\"\"\n",
    "\\begin{table}[h]\n",
    "\\centering\n",
    "\\begin{tabular}{|l|c|}\n",
    "\\hline\n",
    "\\textbf{Dataset} & \\textbf{Density} \\\\\n",
    "\\hline\n",
    "\"\"\"\n",
    "\n",
    "# Add each row to the table\n",
    "for dataset, density in sorted(DENSITIES.items(), key=lambda x: x[1], reverse=True):\n",
    "    dataset = dataset.replace(\"&\", \"\\&\")\n",
    "    latex_table += f\"{dataset} & {density:.2e} \\\\\\\\ \\\\hline \\n\"\n",
    "\n",
    "# End of the LaTeX table\n",
    "latex_table += r\"\"\"\\hline\n",
    "\\end{tabular}\n",
    "\\caption{Comparison between the density of various datasets.}\n",
    "\\label{tab:density-comparison}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMAZON_FASHION_DATASET = r\"resources\\other_datasets\\Amazon_fashion\\AMAZON_FASHION.json\"\n",
    "\n",
    "amazon_fashion_df = pd.read_json(AMAZON_FASHION_DATASET, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_articles = amazon_fashion_df[\"asin\"].nunique()\n",
    "num_customers = amazon_fashion_df[\"reviewerID\"].nunique()\n",
    "num_reviews = amazon_fashion_df.shape[0]\n",
    "print(num_articles, num_customers, num_reviews)\n",
    "amazon_fashion_density = density_of_transactions(num_reviews, num_customers, num_articles)\n",
    "amazon_fashion_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(amazon_fashion_density, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_fashion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOODREADS_DATASET = r\"resources\\other_datasets\\Goodreads\\goodreads_reviews_dedup.json\"\n",
    "\n",
    "goodreads_df = pd.read_json(GOODREADS_DATASET, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = goodreads_df[\"user_id\"].nunique()\n",
    "num_books = goodreads_df[\"book_id\"].nunique()\n",
    "num_reviews = goodreads_df.shape[0]\n",
    "print(num_users, num_books, num_reviews)\n",
    "goodreads_density = density_of_transactions(num_reviews, num_users, num_books)\n",
    "goodreads_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format(goodreads_density, \".7f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOK_RENTAL_PATH = r\"resources\\other_datasets\\book_rental_dataset\\BX-Book-Ratings.csv\"\n",
    "\n",
    "book_rental_df = pd.read_csv(BOOK_RENTAL_PATH, sep=\",\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = book_rental_df[\"user_id\"].nunique()\n",
    "num_books = book_rental_df[\"isbn\"].nunique()\n",
    "num_reviews = book_rental_df.shape[0]\n",
    "\n",
    "book_rental_density = density_of_transactions(num_reviews, num_users, num_books)\n",
    "print(num_users, num_books, num_reviews)\n",
    "print(book_rental_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_rental_df = book_rental_df.drop_duplicates(subset=[\"user_id\", \"isbn\"])\n",
    "\n",
    "num_users = book_rental_df[\"user_id\"].nunique()\n",
    "num_books = book_rental_df[\"isbn\"].nunique()\n",
    "num_reviews = book_rental_df.shape[0]\n",
    "\n",
    "book_rental_density = density_of_transactions(num_reviews, num_users, num_books)\n",
    "print(num_users, num_books, num_reviews)\n",
    "print(book_rental_density)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseline-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
