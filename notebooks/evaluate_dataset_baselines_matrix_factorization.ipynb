{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "print(os.getcwd())\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "\n",
    "from resources.constants import *\n",
    "\n",
    "pictures_df = pd.read_csv(PICTURE_TRIPLETS_CSV_PATH, sep=CSV_SEPARATOR)\n",
    "outfits_df = pd.read_csv(OUTFITS_CSV_PATH, sep=CSV_SEPARATOR)\n",
    "user_triplets_df = pd.read_csv(USER_ACTIVITY_TRIPLETS_CSV_PATH, sep=CSV_SEPARATOR)\n",
    "\n",
    "# CSV files are read as strings, so we need to convert them to lists\n",
    "outfits_df[\"tag_categories\"] = outfits_df[\"tag_categories\"].apply(eval)\n",
    "outfits_df[\"outfit_tags\"] = outfits_df[\"outfit_tags\"].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_orders_df = pd.read_csv(ORIGINAL_ORDERS_CSV_PATH, sep=CSV_SEPARATOR)\n",
    "user_triplets_df = pd.concat([user_triplets_df, original_orders_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.prepare_train_test_splits import translate_user_triplets_to_orders, remove_consecutive_duplicates\n",
    "\n",
    "# Convert triplets into entries for each individual user\n",
    "user_triplets_df = remove_consecutive_duplicates(user_triplets_df)\n",
    "user_orders_df = translate_user_triplets_to_orders(user_triplets_df, outfits_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.prepare_train_test_splits import convert_user_orders_to_train_test_splits\n",
    "\n",
    "# Split the data into train and test sets, with one dataframe with no restirictions on outfits in the test data and one that prohibits repeated outfits\n",
    "# It prints any cases in which it is unable to construct a test set with unique outfits.\n",
    "user_splits_df, user_splits_unique_df = convert_user_orders_to_train_test_splits(user_orders_df, percentage_test=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import implicit\n",
    "from scipy.sparse import coo_matrix\n",
    "from IPython.display import display\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "from src.evaluate_models import evaluate_model, evaluate_hit_rate_at_n, get_outfit_id_from_index\n",
    "\n",
    "def train_als_model(user_splits_df, outfit_column, factors=16, regularization=0.1, iterations=50):\n",
    "    flat_df = user_splits_df.explode(outfit_column)\n",
    "    flat_df[\"value\"] = 1\n",
    "    \n",
    "    unique_outfit_ids = flat_df[outfit_column].unique()\n",
    "    outfit_to_index = {outfit_id: i for i, outfit_id in enumerate(unique_outfit_ids)}\n",
    "    flat_df[\"outfit_index\"] = flat_df[outfit_column].map(outfit_to_index)\n",
    "    \n",
    "    unique_users = pd.unique(flat_df.index)\n",
    "    user_to_index = {user_id: i for i, user_id in enumerate(unique_users)}\n",
    "    flat_df['user_index'] = flat_df.index.map(user_to_index)\n",
    "    \n",
    "    # Debug: Check if there are any negative indices\n",
    "    if (flat_df['outfit_index'] < 0).any():\n",
    "        raise ValueError('Negative outfit_index found')\n",
    "    if (flat_df['user_index'] < 0).any():\n",
    "        raise ValueError('Negative user_index found')\n",
    "\n",
    "    coo = coo_matrix(\n",
    "        (flat_df['value'].values, (flat_df['user_index'].values, flat_df['outfit_index'].values)),\n",
    "        shape=(len(unique_users), len(unique_outfit_ids))\n",
    "    )\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    model = implicit.als.AlternatingLeastSquares(factors=factors, regularization=regularization, iterations=iterations, )\n",
    "    csr = coo.tocsr()\n",
    "    model.fit(csr)\n",
    "\n",
    "    return model, csr, outfit_to_index, user_to_index\n",
    "\n",
    "def run_als_training_loop(df, factors, regularization, run_name=\"\"):\n",
    "    model_ind, csr_ind, outfit_id_to_index, user_to_index = train_als_model(df, \"train_outfit_ids\", factors=factors, regularization=regularization)\n",
    "    model_group, csr_group, outfit_group_to_index, _ = train_als_model(df, \"train_group\", factors=factors, regularization=regularization)\n",
    "\n",
    "    df[\"user_index\"] = df.index.map(user_to_index)\n",
    "\n",
    "    ind_index_to_id = {value : key for key, value in outfit_id_to_index.items()}\n",
    "    df[\"ind_recommendations\"] = df.apply(lambda x: evaluate_model(model_ind, csr_ind, x[\"user_index\"], n=100), axis=1)\n",
    "    df[\"ind_recommendations\"] = df.apply(lambda x: get_outfit_id_from_index(x[\"ind_recommendations\"], ind_index_to_id), axis=1)\n",
    "\n",
    "    group_index_to_id = {value : key for key, value in outfit_group_to_index.items()}\n",
    "    df[\"group_recommendations\"] = df.apply(lambda x: evaluate_model(model_group, csr_group, x[\"user_index\"], n=100), axis=1)\n",
    "    df[\"group_recommendations\"] = df.apply(lambda x: get_outfit_id_from_index(x[\"group_recommendations\"], group_index_to_id), axis=1)\n",
    "\n",
    "    HIT_RATE_COLUMNS = [\"id_hit_rate_at_100\", \"id_hit_rate_at_10\", \"group_hit_rate_at_100\", \"group_hit_rate_at_10\"]\n",
    "    df[\"id_hit_rate_at_100\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_outfit_id\"], x[\"ind_recommendations\"], n=100), axis=1)\n",
    "    df[\"id_hit_rate_at_10\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_outfit_id\"], x[\"ind_recommendations\"], n=10), axis=1)\n",
    "    df[\"group_hit_rate_at_100\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_group\"], x[\"group_recommendations\"], n=100), axis=1)\n",
    "    df[\"group_hit_rate_at_10\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_group\"], x[\"group_recommendations\"], n=10), axis=1)\n",
    "\n",
    "    print(f\"Run name: {run_name} Factors: {factors}, Regularization: {regularization}\")\n",
    "    display(df[HIT_RATE_COLUMNS].mean())\n",
    "    print(\"=\"*20)\n",
    "\n",
    "    result_dict = {column: df[column].mean() for column in HIT_RATE_COLUMNS}\n",
    "\n",
    "    return df, (factors, regularization, df[\"group_hit_rate_at_100\"].mean(), run_name), result_dict\n",
    "    \n",
    "\n",
    "\n",
    "TEST_FACTORS = [32]\n",
    "TEST_REGULARIZATIONS = [0.01]\n",
    "run_dataframes = [(user_splits_df, \"All Outfits\"), (user_splits_unique_df, \"Unique Outfit\")]\n",
    "\n",
    "test_permutations = list(product(TEST_FACTORS, TEST_REGULARIZATIONS))\n",
    "test_permutations = [(t_factors, t_reg, run_df) for t_factors, t_reg, run_df in product(TEST_FACTORS, TEST_REGULARIZATIONS, run_dataframes)]\n",
    "\n",
    "group_hr_10_means, result_dicts = [], []\n",
    "for test_factors, test_regularization, (df, run_name) in test_permutations:\n",
    "    df, result, result_dict = run_als_training_loop(df, test_factors, test_regularization, run_name=run_name)\n",
    "    result_dicts.append(result_dict)\n",
    "    group_hr_10_means.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyperclip\n",
    "\n",
    "def format_dicts_into_latex(all_dict, ind_dict, precision=4):\n",
    "    first_row = f\"ALS Ind & {all_dict['id_hit_rate_at_10']:.{precision}f} & {all_dict['id_hit_rate_at_100']:.{precision}f} & {ind_dict['id_hit_rate_at_10']:.{precision}f} & {ind_dict['id_hit_rate_at_100']:.{precision}f} \\\\\\\\\"\n",
    "    second_row = f\"ALS Groups & {all_dict['group_hit_rate_at_10']:.{precision}f} & {all_dict['group_hit_rate_at_100']:.{precision}f} & {ind_dict['group_hit_rate_at_10']:.{precision}f} & {ind_dict['group_hit_rate_at_100']:.{precision}f} \\\\\\\\\\\\hline\"\n",
    "    full_string = first_row + \"\\n\" + second_row + \"\\n\"\n",
    "    print(full_string)\n",
    "    pyperclip.copy(full_string)\n",
    "\n",
    "all_dict, ind_dict = result_dicts\n",
    "format_dicts_into_latex(all_dict, ind_dict, precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import implicit\n",
    "from scipy.sparse import coo_matrix\n",
    "from IPython.display import display\n",
    "from itertools import product\n",
    "\n",
    "from implicit.bpr import BayesianPersonalizedRanking\n",
    "\n",
    "\n",
    "def train_bpr_model(user_splits_df, outfit_column, factors=16, regularization=0.1, learning_rate=0.1, iterations=500):\n",
    "    flat_df = user_splits_df.explode(outfit_column)\n",
    "    flat_df[\"value\"] = 1\n",
    "    \n",
    "    unique_outfit_ids = flat_df[outfit_column].unique()\n",
    "    outfit_to_index = {outfit_id: i for i, outfit_id in enumerate(unique_outfit_ids)}\n",
    "    flat_df[\"outfit_index\"] = flat_df[outfit_column].map(outfit_to_index)\n",
    "    \n",
    "    unique_users = pd.unique(flat_df.index)\n",
    "    user_to_index = {user_id: i for i, user_id in enumerate(unique_users)}\n",
    "    flat_df['user_index'] = flat_df.index.map(user_to_index)\n",
    "    \n",
    "    # Debug: Check if there are any negative indices\n",
    "    if (flat_df['outfit_index'] < 0).any():\n",
    "        raise ValueError('Negative outfit_index found')\n",
    "    if (flat_df['user_index'] < 0).any():\n",
    "        raise ValueError('Negative user_index found')\n",
    "\n",
    "    coo = coo_matrix(\n",
    "        (flat_df['value'].values, (flat_df['user_index'].values, flat_df['outfit_index'].values)),\n",
    "        shape=(len(unique_users), len(unique_outfit_ids))\n",
    "    )\n",
    "    \n",
    "    np.random.seed(43)\n",
    "    model = BayesianPersonalizedRanking(factors=factors, regularization=regularization, iterations=iterations, learning_rate=learning_rate)\n",
    "    csr = coo.tocsr()\n",
    "    model.fit(csr)\n",
    "    \n",
    "    return model, csr, outfit_to_index, user_to_index\n",
    "\n",
    "\n",
    "def run_bpr_training_loop(df, factors, regularization, learning_rate, run_name=\"\"):\n",
    "    model_ind, csr_ind, outfit_id_to_index, user_to_index = train_bpr_model(df, \"train_outfit_ids\", factors=factors, regularization=regularization, learning_rate=learning_rate)\n",
    "    model_group, csr_group, outfit_group_to_index, _ = train_bpr_model(df, \"train_group\", factors=factors, regularization=regularization, learning_rate=learning_rate)\n",
    "\n",
    "    df[\"user_index\"] = df.index.map(user_to_index)\n",
    "\n",
    "    ind_index_to_id = {value : key for key, value in outfit_id_to_index.items()}\n",
    "    df[\"ind_recommendations\"] = df.apply(lambda x: evaluate_model(model_ind, csr_ind, x[\"user_index\"], n=100), axis=1)\n",
    "    df[\"ind_recommendations\"] = df.apply(lambda x: get_outfit_id_from_index(x[\"ind_recommendations\"], ind_index_to_id), axis=1)\n",
    "\n",
    "    group_index_to_id = {value : key for key, value in outfit_group_to_index.items()}\n",
    "    df[\"group_recommendations\"] = df.apply(lambda x: evaluate_model(model_group, csr_group, x[\"user_index\"], n=100), axis=1)\n",
    "    df[\"group_recommendations\"] = df.apply(lambda x: get_outfit_id_from_index(x[\"group_recommendations\"], group_index_to_id), axis=1)\n",
    "\n",
    "    HIT_RATE_COLUMNS = [\"id_hit_rate_at_100\", \"id_hit_rate_at_10\", \"group_hit_rate_at_100\", \"group_hit_rate_at_10\"]\n",
    "    df[\"id_hit_rate_at_100\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_outfit_id\"], x[\"ind_recommendations\"], n=100), axis=1)\n",
    "    df[\"id_hit_rate_at_10\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_outfit_id\"], x[\"ind_recommendations\"], n=10), axis=1)\n",
    "    df[\"group_hit_rate_at_100\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_group\"], x[\"group_recommendations\"], n=100), axis=1)\n",
    "    df[\"group_hit_rate_at_10\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_group\"], x[\"group_recommendations\"], n=10), axis=1)\n",
    "\n",
    "    print(f\"Run name: {run_name} Factors: {factors}, Regularization: {regularization}\")\n",
    "    display(df[HIT_RATE_COLUMNS].mean())\n",
    "    print(\"=\"*20)\n",
    "\n",
    "    result_dict = {column: df[column].mean() for column in HIT_RATE_COLUMNS}\n",
    "\n",
    "    return df, (factors, regularization, df[\"group_hit_rate_at_100\"].mean(), df[\"id_hit_rate_at_100\"].mean(), run_name), result_dict\n",
    "\n",
    "\n",
    "TEST_FACTORS = [128]\n",
    "TEST_REGULARIZATIONS = [0.01]\n",
    "TEST_LEARNING_RATES = [0.01]\n",
    "#run_dataframes = [user_splits_df]\n",
    "run_dataframes = [(user_splits_df, \"All Outfits\"), (user_splits_unique_df, \"Unique Outfit\")]\n",
    "\n",
    "test_permutations = list(product(TEST_FACTORS, TEST_REGULARIZATIONS, TEST_LEARNING_RATES))\n",
    "test_permutations = [(t_factors, t_reg, t_lr, run_df) for t_factors, t_reg, t_lr, run_df in product(TEST_FACTORS, TEST_REGULARIZATIONS, TEST_LEARNING_RATES, run_dataframes)]\n",
    "\n",
    "group_hr_10_means, result_dicts, result_dataframes = [], [], []\n",
    "for test_factors, test_regularization, test_learning_rate, (df, run_name) in test_permutations:\n",
    "    df, result, result_dict = run_bpr_training_loop(df, test_factors, test_regularization, test_learning_rate, run_name=run_name)\n",
    "    result_dicts.append(result_dict)\n",
    "    group_hr_10_means.append(result)\n",
    "    result_dataframes.append(df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the exact hit items for individual and group recommendations overlap for BPR\n",
    "\n",
    "standard_result_df, unique_result_df = result_dataframes\n",
    "print(standard_result_df[\"id_hit_rate_at_100\"].mean(), unique_result_df[\"id_hit_rate_at_100\"].mean())\n",
    "\n",
    "unique_columns = [\"u_\" + column_name for column_name in unique_result_df.columns]\n",
    "unique_result_df.columns = unique_columns\n",
    "\n",
    "def check_if_overlap_in_hit(row, column_name):\n",
    "    hit_standard = row[column_name]\n",
    "    hit_unique = row[\"u_\" + column_name]\n",
    "    return hit_standard > 0.1 and hit_unique > 0.1\n",
    "\n",
    "all_results = pd.concat([standard_result_df, unique_result_df], axis=1)\n",
    "all_results[\"overlap_100\"] = all_results.apply(lambda x: check_if_overlap_in_hit(x, \"id_hit_rate_at_100\"), axis=1)\n",
    "all_results[\"overlap_100\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyperclip\n",
    "\n",
    "def format_dicts_into_latex(all_dict, ind_dict, precision=4):\n",
    "    first_row = f\"BPR Ind & {all_dict['id_hit_rate_at_10']:.{precision}f} & {all_dict['id_hit_rate_at_100']:.{precision}f} & {ind_dict['id_hit_rate_at_10']:.{precision}f} & {ind_dict['id_hit_rate_at_100']:.{precision}f} \\\\\\\\\"\n",
    "    second_row = f\"BPR Groups & {all_dict['group_hit_rate_at_10']:.{precision}f} & {all_dict['group_hit_rate_at_100']:.{precision}f} & {ind_dict['group_hit_rate_at_10']:.{precision}f} & {ind_dict['group_hit_rate_at_100']:.{precision}f} \\\\\\\\\\\\hline\"\n",
    "    full_string = first_row + \"\\n\" + second_row + \"\\n\"\n",
    "    print(full_string)\n",
    "    pyperclip.copy(full_string)\n",
    "\n",
    "all_dict, ind_dict = result_dicts\n",
    "format_dicts_into_latex(all_dict, ind_dict, precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import implicit\n",
    "from scipy.sparse import coo_matrix\n",
    "from IPython.display import display\n",
    "from itertools import product\n",
    "\n",
    "from implicit.lmf import LogisticMatrixFactorization\n",
    "\n",
    "def train_lmf_model(user_splits_df, outfit_column, factors=16, regularization=0.1, learning_rate=0.1, iterations=500):\n",
    "    flat_df = user_splits_df.explode(outfit_column)\n",
    "    flat_df[\"value\"] = 1\n",
    "    \n",
    "    unique_outfit_ids = flat_df[outfit_column].unique()\n",
    "    outfit_to_index = {outfit_id: i for i, outfit_id in enumerate(unique_outfit_ids)}\n",
    "    flat_df[\"outfit_index\"] = flat_df[outfit_column].map(outfit_to_index)\n",
    "    \n",
    "    unique_users = pd.unique(flat_df.index)\n",
    "    user_to_index = {user_id: i for i, user_id in enumerate(unique_users)}\n",
    "    flat_df['user_index'] = flat_df.index.map(user_to_index)\n",
    "    \n",
    "    # Debug: Check if there are any negative indices\n",
    "    if (flat_df['outfit_index'] < 0).any():\n",
    "        raise ValueError('Negative outfit_index found')\n",
    "    if (flat_df['user_index'] < 0).any():\n",
    "        raise ValueError('Negative user_index found')\n",
    "\n",
    "    coo = coo_matrix(\n",
    "        (flat_df['value'].values, (flat_df['user_index'].values, flat_df['outfit_index'].values)),\n",
    "        shape=(len(unique_users), len(unique_outfit_ids))\n",
    "    )\n",
    "    \n",
    "    np.random.seed(43)\n",
    "    model = LogisticMatrixFactorization(factors=factors, regularization=regularization, iterations=iterations, learning_rate=learning_rate)\n",
    "    csr = coo.tocsr()\n",
    "    model.fit(csr)\n",
    "    \n",
    "    return model, csr, outfit_to_index, user_to_index\n",
    "\n",
    "def run_lmf_training_loop(df, factors, regularization, learning_rate, run_name=\"\"):\n",
    "    model_ind, csr_ind, outfit_id_to_index, user_to_index = train_lmf_model(df, \"train_outfit_ids\", factors=factors, regularization=regularization, learning_rate=learning_rate)\n",
    "    model_group, csr_group, outfit_group_to_index, _ = train_lmf_model(df, \"train_group\", factors=factors, regularization=regularization, learning_rate=learning_rate)\n",
    "\n",
    "    df[\"user_index\"] = df.index.map(user_to_index)\n",
    "\n",
    "    ind_index_to_id = {value : key for key, value in outfit_id_to_index.items()}\n",
    "    df[\"ind_recommendations\"] = df.apply(lambda x: evaluate_model(model_ind, csr_ind, x[\"user_index\"], n=100), axis=1)\n",
    "    df[\"ind_recommendations\"] = df.apply(lambda x: get_outfit_id_from_index(x[\"ind_recommendations\"], ind_index_to_id), axis=1)\n",
    "\n",
    "    group_index_to_id = {value : key for key, value in outfit_group_to_index.items()}\n",
    "    df[\"group_recommendations\"] = df.apply(lambda x: evaluate_model(model_group, csr_group, x[\"user_index\"], n=100), axis=1)\n",
    "    df[\"group_recommendations\"] = df.apply(lambda x: get_outfit_id_from_index(x[\"group_recommendations\"], group_index_to_id), axis=1)\n",
    "\n",
    "    HIT_RATE_COLUMNS = [\"id_hit_rate_at_100\", \"id_hit_rate_at_10\", \"group_hit_rate_at_100\", \"group_hit_rate_at_10\"]\n",
    "    df[\"id_hit_rate_at_100\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_outfit_id\"], x[\"ind_recommendations\"], n=100), axis=1)\n",
    "    df[\"id_hit_rate_at_10\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_outfit_id\"], x[\"ind_recommendations\"], n=10), axis=1)\n",
    "    df[\"group_hit_rate_at_100\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_group\"], x[\"group_recommendations\"], n=100), axis=1)\n",
    "    df[\"group_hit_rate_at_10\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_group\"], x[\"group_recommendations\"], n=10), axis=1)\n",
    "\n",
    "    print(f\"Run name: {run_name} Factors: {factors}, Regularization: {regularization}\")\n",
    "    display(df[HIT_RATE_COLUMNS].mean())\n",
    "    print(\"=\"*20)\n",
    "\n",
    "    result_dict = {column: df[column].mean() for column in HIT_RATE_COLUMNS}\n",
    "\n",
    "    return df, (factors, regularization, df[\"group_hit_rate_at_10\"].mean(), df[\"id_hit_rate_at_10\"].mean(), run_name), result_dict\n",
    "\n",
    "\n",
    "TEST_FACTORS = [128]\n",
    "TEST_REGULARIZATIONS = [0.01]\n",
    "TEST_LEARNING_RATES = [0.01]\n",
    "#run_dataframes = [user_splits_df]\n",
    "run_dataframes = [(user_splits_df, \"All Outfits\"), (user_splits_unique_df, \"Unique Outfit\")]\n",
    "\n",
    "test_permutations = list(product(TEST_FACTORS, TEST_REGULARIZATIONS, TEST_LEARNING_RATES))\n",
    "test_permutations = [(t_factors, t_reg, t_lr, run_df) for t_factors, t_reg, t_lr, run_df in product(TEST_FACTORS, TEST_REGULARIZATIONS, TEST_LEARNING_RATES, run_dataframes)]\n",
    "\n",
    "group_hr_10_means, result_dicts = [], []\n",
    "for test_factors, test_regularization, test_learning_rate, (df, run_name) in test_permutations:\n",
    "    df, result, result_dict = run_lmf_training_loop(df, test_factors, test_regularization, test_learning_rate, run_name=run_name)\n",
    "    result_dicts.append(result_dict)\n",
    "    group_hr_10_means.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dicts_into_latex(all_dict, ind_dict, precision=4):\n",
    "    first_row = f\"LMF Ind: & {all_dict['id_hit_rate_at_10']:.{precision}f} & {all_dict['id_hit_rate_at_100']:.{precision}f} & {ind_dict['id_hit_rate_at_10']:.{precision}f} & {ind_dict['id_hit_rate_at_100']:.{precision}f} \\\\\\\\\"\n",
    "    second_row = f\"LMF Groupd: & {all_dict['group_hit_rate_at_10']:.{precision}f} & {all_dict['group_hit_rate_at_100']:.{precision}f} & {ind_dict['group_hit_rate_at_10']:.{precision}f} & {ind_dict['group_hit_rate_at_100']:.{precision}f} \\\\\\\\\\\\hline\"\n",
    "    print(first_row)\n",
    "    print(second_row)\n",
    "\n",
    "all_dict, ind_dict = result_dicts\n",
    "format_dicts_into_latex(all_dict, ind_dict, precision=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fashionEnv)",
   "language": "python",
   "name": "fashionenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
